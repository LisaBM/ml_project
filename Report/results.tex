When choosing ... many training points and .... many testing points our algorithm was correct in ... of the cases. Include things here...?


Linear and Gaussian.

In general ECOC?

Where do we bring in cross validation?

General Conclusions? Difficulties?

For One-vs-All linear almost (<5 \%) no correct result, barycenters improved things a lot  (maybe take out of table if its too bad...)

One-vs-All Gauss: a lot better, I think especially more training data was helpful

ECOC 

Table for overview of results 

Each time we tested with ... 1000 (!!!!!!!!!!!) test points. The given training data set that we had was very large, so we always had data to test our results that was not used for training. 

Talk about average compute times. Or did Paul already say something about that beforehand? 

Talk about the 1500 issue or better not?


% Ich hätte ganz links oben gerne eine schräge Linie
% \lft{n}\rt{k}}
% \lft{classifier}\rt{no of training points}	
\begin{table}[ht!]
	\centering
	\caption{Overview Results}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|} \hline
\multicolumn{1}{|p{2cm}|}{no of training points classifier} & \multicolumn{1}{p{2cm}|}{One-vs-One uniquely classfied correctly linear} & \multicolumn{1}{p{2cm}|}{One-vs-One w/ barycenters linear} & \multicolumn{1}{p{2cm}|}{One-vs-One uniquely classfied correctly Gaussian} &  \multicolumn{1}{p{2cm}|}{One-vs-One w/ barycenters Gaussian} & \multicolumn{1}{p{2cm}|}{ECOC linear} & \multicolumn{1}{p{2cm}|}{ECOC Gaussian} \\ \hline \hline
	500	& 659 & 741 & 754 & 833 & 742 & 874 \\ \hline
	1000	& 682 & 750 & 843 & 890 & 780 & 927 \\ \hline
	2000	& 702 & 764 & 898 & 919 &  & 943 \\ \hline
	5000	& 700 & 738 & 889 & 916 &  & 952 \\ \hline
	10000	&  &  & 880 & 906 &  & 954 \\ \hline
	\end{tabular}
\end{table}

