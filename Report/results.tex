This is the largest programming project any one of has ever worked on and neither of us had done much with Python before or had any other machine learning experience. So at any given time there was always a great variety of difficulties at hand. And because we implemented everything ourselves the problem could be literally anywhere, from misunderstanding the pseudocode we used, over float and integer division or git merging issues to immense troubles with the internal solvers for the optimization problem. But because of that every little success was a source of joy which grew with every working block of code we managed to compile.

\smallskip
The overall structure of our program looks as follows. We wrote our own \texttt{mySVMclass}, which is a self contained object with a number of attributes and callable functions, which includes the \texttt{SMOsolver} and \texttt{crossValidation}. We then have separate .ipynb notebooks for the two classification algorithms where we specify training data sets, the kernel, the different parameters and create instances of our \texttt{mySVMclass}. Especially in the case of the gaussian kernel finding suitable parameters was very essential. We therefore wrote a separate notebook where we systematically test them and determine which ones seem optimal. We also automatically save our trained SVMs for the different sized training data in binary format. We also visualized toy data sets in lower dimensions to better understand how our algorithms behave in different cases.

\begin{table}[ht!]
	\centering
	\caption{\textbf{Overview Results of Correctly Classified Digits}}
	\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|l|l|} \hline
		\multicolumn{1}{|p{1.8cm}|}{\vspace*{.7 cm}\# training points} &
		\multicolumn{1}{p{1.8cm}|}{\vspace*{0 cm}\hbox{One-vs-All} uniquely classfied, linear} &
		\multicolumn{1}{p{1.8cm}|}{\vspace*{0 cm}\hbox{One-vs-All} with bary- centers, linear} &
		\multicolumn{1}{p{1.8cm}|}{\vspace*{0 cm}\hbox{One-vs-All} uniquely classfied, Gaussian} &
		\multicolumn{1}{p{1.8cm}|}{\vspace*{0 cm}\hbox{One-vs-All} with bary-centers, Gaussian} &
		\multicolumn{1}{p{1.8cm}|}{\vspace*{.7 cm}ECOC, \hbox{linear}} &
		\multicolumn{1}{p{1.8cm}|}{\vspace*{.7 cm}ECOC, Gaussian} \\ \hline \hline
		500	& 65.9\% & 74.1\% & 75.4\% & 83.3\% & 74.2\% & 87.4\% \\ \hline
		1000	& 68.2\% & 75.0\% & 84.3\% & 89.0\% & 78.0\% & 92.7\% \\ \hline
		2000	& 70.2\% & 76.4\% & 89.8\% & 91.9\% & 77.8\% & 94.3\% \\ \hline
		5000	& 70.0\% & 73.8\% & 88.9\% & 91.6\% & 82.0\% & 95.2\% \\ \hline
		10000	& 64.6\% & 67.5\% & 88.0\% & 90.6\% & 82.5\% & 95.4\% \\ \hline
	\end{tabular}
\end{table}

\smallskip
Our given data set included 42,000 handwritten digits. We never used all of them for training because this large amount of training data simply exceeded our available compute power. But from the table below we can see that it would probably not have improved our results considerably or might even have worsened them. And this way we always had engouh labeled data to test and verify our results with. In the table you can find the results of the different multi-class classifiers. For the One-vs-All approach we give numbers for how many labels were found correctly with and without using additional classification by location of the barycenters, so that one can really see how many uniquely classified data points are labeled correctly. The percentages are derived from always testing with 1,000 data points that were of course not used for training beforehand. Unsurprisingly ECOC had longer run times than the One-vs-All classifier, it has to train $15$ instead of only $10$ and the computation with the Gaussian kernel took longer than with the linear kernel, which was also to be expected because of its higher complexity (more detail?). For 10,000 training points ECOC with linear kernel took $1$h $16$ min and ECOC with gaussian kernel took $2$ h $26$ min for training.  

\smallskip
As expected from theoretical considerations the Error-Correcting Output Codes performed better than the One-vs-All classification for training sets of any size. However we were surprised how well One-vs-All with the gaussian kernel worked in the end. Every picture of a hand-written digit gets turned into a vector of size $784$  ($=28^2$), it was not clear that the output data would be anywhere close to being linearly separable so we were also suprised to see the linear classifiers working at all, especially in the first case were not a single ambiguity or mistake could be corrected. With an increase of training points the results first increase across the board. The performance of classifiers with linear kernel then often starts to decrease, sometimes drastically, with training sets of size 2,000. We assume that this phenomenon occurs because the more training data we have the harder it gets to linearly separate it. 

% Ich hätte ganz links oben gerne eine schräge Linie
% \lft{n}\rt{k}}
% \lft{classifier}\rt{no of training points}	


We have learned a lot in the past 4 weeks and although this program does not (yet?) win us a kaggle competition we are in general (very) satisfied with the overall outcome of the project and especially with our success rate of over $95$\%.
