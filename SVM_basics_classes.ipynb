{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from scipy.optimize import minimize\n",
    "import cvxopt\n",
    "from cvxopt import matrix, solvers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('C:/Users/LMatt/OneDrive/Dokumente/Mathe/Machine Learning/Projekt/digits_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [\"%s%s\" %(\"pixel\",pixel_no) for pixel_no in range(0,28**2)]\n",
    "train_images = np.array(train[images], dtype=np.float)/100\n",
    "#dimensionserhoehung, damit am ende b = 0\n",
    "train_images = np.concatenate((train_images, np.ones((len(train_images),1))), axis = 1)\n",
    "\n",
    "train_labels = np.array(train['label'])\n",
    "label0 = np.array([1 if i==0 else -1 for i in train_labels])\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.478958899510353"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mal gucken, wie weit die Datenpunkte so ungefähr auseinander liegen, damit wir wissen wie groß sigma sein muss\n",
    "np.linalg.norm(train_images[130] - train_images[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(x1, x2, sigma):\n",
    "    return np.exp(-sigma*np.linalg.norm(x1-x2)**2)\n",
    "\n",
    "def gk(x1,x2):\n",
    "    sigma = float(1)/100\n",
    "    return gaussian_kernel(x1, x2, sigma)\n",
    "\n",
    "def scalar_product(x1, x2):\n",
    "    return np.dot(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x28f1eb38>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgkAAAFkCAYAAACq4KjhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndMLxutNcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2917ab00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "x = np.linspace(-50, 50, 100)\n",
    "y = [gk(0,i) for i in x]\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def minimize_Lagrangian(training_data, training_labels, penalty, kernel):\n",
    "    no_samples = len(training_data)\n",
    "    t = np.diag(training_labels[:no_samples])\n",
    "    tm = -t\n",
    "    K = matrix(pairwise_kernels(training_data, metric = kernel),tc='d')\n",
    "    p = matrix(training_labels,tc='d')\n",
    "    A = matrix(1., ( 1,no_samples),tc='d')\n",
    "    b = matrix(0.,(1,1),tc='d')\n",
    "    G = matrix(np.concatenate((tm,t)),tc='d')\n",
    "    h = matrix(np.concatenate((matrix(0.,(no_samples,1 )), matrix(float(penalty),(no_samples,1)))),tc='d')\n",
    "    sol = solvers.qp(-K, p, G, h, A, b)\n",
    "    x = np.reshape(np.array(sol['x']), no_samples)\n",
    "    a = np.array([x[i]*training_labels[i] for i in range(no_samples)])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assemble_kernelmatrix(data, data2 = None, kernel = scalar_product):\n",
    "    if data2 == None:\n",
    "        K = pairwise_kernels(data, metric = kernel)\n",
    "    else:\n",
    "        K = pairwise_kernels(data2, data, metric = kernel)\n",
    "    return K\n",
    "\n",
    "def minimize_Lagrangian2(training_data, training_labels, penalty, kernel, kernelmatrix):\n",
    "    no_samples = len(training_data)\n",
    "    training_labels = matrix(training_labels, (no_samples, 1))\n",
    "    K = kernelmatrix\n",
    "    T = np.dot(training_labels, np.transpose(training_labels))\n",
    "    Q = matrix(np.multiply(K, T), (no_samples, no_samples), tc='d')\n",
    "    A = matrix(training_labels, ( 1, no_samples),tc='d')\n",
    "    print(np.shape(A))\n",
    "    p = matrix(-1., ( no_samples, 1),tc='d')\n",
    "    b = matrix(0.,(1,1),tc='d')\n",
    "    G = matrix(np.concatenate((-np.identity(no_samples),np.identity(no_samples))),tc='d')\n",
    "    h = matrix(np.concatenate((matrix(0.,(no_samples,1 )), matrix(float(penalty),(no_samples,1)))),tc='d')\n",
    "    sol = solvers.qp(Q, p, G, h, A, b)\n",
    "    a = np.reshape(np.array(sol['x']), no_samples)\n",
    "    return a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimize_Lagrangian3(training_data, training_labels, penalty, kernel):\n",
    "\n",
    "    no_samples = len(training_data)\n",
    "    K = pairwise_kernels(training_data, metric = kernel)\n",
    "    def Lagrangian(x):\n",
    "        return 0.5*np.dot(np.dot(np.transpose(x),Q),x) - np.dot(np.transpose(p),x)\n",
    "    T = np.dot(training_labels, np.transpose(training_labels))\n",
    "    Q = np.multiply(K, T)\n",
    "    A = training_labels\n",
    "    p = np.ones(no_samples)\n",
    "    b = np.array(0.)\n",
    "    G = np.concatenate((-np.identity(no_samples),np.identity(no_samples)))\n",
    "    h = np.concatenate((np.zeros(no_samples), penalty*np.ones(no_samples)))\n",
    "    '''K = np.array(K)\n",
    "    q = np.array(q)\n",
    "    A = np.array(A)\n",
    "    b = np.array(b)\n",
    "    G = np.array(G)\n",
    "    h = np.array(h)'''\n",
    "    a0 = np.zeros((no_samples, 1))\n",
    "    constraint1 = {'type': 'ineq',\n",
    "                  'fun': lambda x: -np.dot(G,x)+h,\n",
    "                  'jac': lambda x: -G}\n",
    "    constraint2 ={'type': 'eq',\n",
    "                 'fun': lambda x: np.dot(A,x)+b,\n",
    "                 'jac': lambda x: A}\n",
    "    options = {'maxiter': 100000}\n",
    "    a=scipy.optimize.minimize(Lagrangian, a0, constraints=[constraint1, constraint2], jac = lambda x: np.dot(Q,x), hess = lambda x: Q,method = 'Powell', options = options)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "minimize_Lagrangian2() takes exactly 5 arguments (4 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c732ec96fcbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdaten\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize_Lagrangian2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdaten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalar_product\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: minimize_Lagrangian2() takes exactly 5 arguments (4 given)"
     ]
    }
   ],
   "source": [
    "C = 1000\n",
    "daten = np.array([[0,1], [1, 0],[2,0], [1,2], [0, 0.9]])\n",
    "labels = np.array([-1, 1, 1, -1, 1])\n",
    "a = minimize_Lagrangian2(daten, labels, C, scalar_product)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "minimize_Lagrangian2() takes exactly 5 arguments (4 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b2756c466e22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mno_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mno_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize_Lagrangian2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalar_product\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: minimize_Lagrangian2() takes exactly 5 arguments (4 given)"
     ]
    }
   ],
   "source": [
    "no_samples = 100\n",
    "C = 1000\n",
    "data = train_images[:no_samples]\n",
    "label = np.array(label0[:no_samples])\n",
    "a = minimize_Lagrangian2(data, label, C, scalar_product)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class mySVM:\n",
    "    \n",
    "    def __init__(self, kernel = gk, penalty = 1, sigma = 0.01):\n",
    "        self.sigma = sigma\n",
    "        self.kernel = kernel\n",
    "        self.penalty = penalty\n",
    "        self.kernelmatrix_for_fit = None\n",
    "        self.kernelmatrix_for_predict = None\n",
    "        \n",
    "    def fit(self,training_data, training_labels):\n",
    "        if self.kernelmatrix_for_fit == None:\n",
    "            self.kernelmatrix_for_fit  = assemble_kernelmatrix(training_data, kernel = self.kernel)\n",
    "        a = minimize_Lagrangian2(training_data, training_labels,self.penalty, self.kernel, kernelmatrix = self.kernelmatrix_for_fit)    \n",
    "        self.a = a\n",
    "        self.training_data = training_data\n",
    "        self.training_labels = training_labels\n",
    "\n",
    "        \n",
    "    def predict(self, newdata):\n",
    "        if self.kernelmatrix_for_predict == None:\n",
    "            self.kernelmatrix_for_predict = assemble_kernelmatrix(self.training_data, data2 = newdata, kernel = self.kernel)\n",
    "        k = self.kernelmatrix_for_predict\n",
    "        alphatimeslabel = np.multiply(self.a, self.training_labels)\n",
    "        prediction = np.array([np.dot(k[i,:], alphatimeslabel) for i in range(len(newdata))])\n",
    "        return np.sign(prediction)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 100L)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0996e+01 -1.2263e+02  4e+02  1e+00  5e-16\n",
      " 1: -9.2065e+00 -5.0377e+01  5e+01  8e-02  5e-16\n",
      " 2: -1.0147e+01 -2.8436e+01  3e+01  3e-02  1e-15\n",
      " 3: -9.3626e+00 -1.3769e+01  7e+00  7e-03  7e-15\n",
      " 4: -9.0281e+00 -9.2392e+00  4e-01  3e-04  3e-15\n",
      " 5: -9.0003e+00 -9.0024e+00  4e-03  3e-06  4e-15\n",
      " 6: -9.0000e+00 -9.0000e+00  4e-05  3e-08  3e-15\n",
      " 7: -9.0000e+00 -9.0000e+00  4e-07  3e-10  3e-15\n",
      "Optimal solution found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMatt\\Anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68, 45)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C=1\n",
    "no = 100 #Anzahl an Trainingsdaten, die zum fitten verwendet werden\n",
    "no2 = 100 #Anzahl an Trainingsdaten, die nicht zum fitten verwendet wurden, mit denen wir unsere SVM testen\n",
    "s = 0.0001\n",
    "svm = mySVM(kernel = gk, penalty=C, sigma = s )\n",
    "svm.fit(train_images[:no], train_labels[:no])\n",
    "pred = svm.predict(train_images[:no+no2])\n",
    "x = list(pred == label0[:no+no2])\n",
    "sum(x[:no]), sum(x[-no2:])\n",
    "#[svm.a[i] for i in range(no) if label0[i]==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([37, 54,  0,  0,  0,  0,  0,  0,  0,  9], dtype=int64),\n",
       " array([ 0.00171607,  0.10154446,  0.20137285,  0.30120124,  0.40102964,\n",
       "         0.50085803,  0.60068642,  0.70051481,  0.80034321,  0.9001716 ,\n",
       "         0.99999999]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAFkCAYAAAC0KZhSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bfc5780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(svm2.a)\n",
    "np.histogram(svm2.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 100L)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.3653e+01 -1.4967e+02  6e+02  2e+00  5e-16\n",
      " 1: -1.2523e+01 -6.9010e+01  6e+01  2e-02  5e-16\n",
      " 2: -1.2495e+01 -1.3673e+01  1e+00  3e-04  5e-16\n",
      " 3: -1.2585e+01 -1.2642e+01  6e-02  7e-06  1e-16\n",
      " 4: -1.2590e+01 -1.2594e+01  3e-03  3e-07  7e-17\n",
      " 5: -1.2591e+01 -1.2591e+01  2e-04  1e-08  8e-17\n",
      " 6: -1.2591e+01 -1.2591e+01  1e-05  2e-10  1e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "svm2 = mySVM(kernel = gk, penalty=C, sigma = s )\n",
    "svm2.fit(train_images[:no], label0[:no])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      " -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1.  1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.  1. -1.\n",
      " -1. -1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMatt\\Anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel\\__main__.py:20: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " -1,\n",
       " 1,\n",
       " -1]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.array([0 if alpha<10**(-2) else alpha for alpha in svm2.a])\n",
    "\n",
    "svm2.a = a\n",
    "pred = svm2.predict(train_images[:no+no2])\n",
    "x = list(pred == label0[:no+no2])\n",
    "sum(x[:no]), sum(x[-no2:])\n",
    "print(pred)\n",
    "[label0[i] for i in range(100) if not a[i]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   1.77260721e-05,   7.31712345e-03, ...,\n",
       "          1.90201980e-04,   5.19817900e-04,   7.06048302e-05],\n",
       "       [  1.77260721e-05,   1.00000000e+00,   3.05014602e-05, ...,\n",
       "          7.82559970e-04,   8.25062921e-05,   1.92963019e-04],\n",
       "       [  7.31712345e-03,   3.05014602e-05,   1.00000000e+00, ...,\n",
       "          2.33936698e-04,   4.21375583e-04,   7.62116668e-05],\n",
       "       ..., \n",
       "       [  1.32510059e-04,   2.68179264e-05,   4.32307248e-04, ...,\n",
       "          9.59979232e-05,   5.22001077e-05,   3.29848564e-05],\n",
       "       [  3.00030026e-04,   1.83875805e-04,   4.60813109e-04, ...,\n",
       "          1.26363738e-04,   1.51239648e-05,   3.20720029e-04],\n",
       "       [  6.05561705e-03,   4.49723366e-05,   1.12655497e-03, ...,\n",
       "          5.91032825e-04,   9.98584375e-05,   1.71068756e-04]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svm2.kernelmatrix_for_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "no = 1000\n",
    "images0 = []\n",
    "imagesnot0 = []\n",
    "i = 0\n",
    "while len(images0)<no/2. or len(imagesnot0) < no/2.:\n",
    "    if label0[i]==1 and len(images0)<no/2.:\n",
    "        images0.append(train_images[i])\n",
    "    elif label0[i]==-1 and len(imagesnot0) < no/2.: \n",
    "        imagesnot0.append(train_images[i])\n",
    "    i=i+1\n",
    "print(len(images0))\n",
    "trainingdata_even = np.concatenate((np.array(images0), np.array(imagesnot0)))\n",
    "traininglabels_even = np.concatenate((np.ones(len(images0)), -np.ones(len(imagesnot0))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 1000L)\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.8275e+02 -1.7319e+03  5e+03  2e+00  1e-15\n",
      " 1: -1.7000e+02 -9.2010e+02  8e+02  3e-13  5e-16\n",
      " 2: -1.9212e+02 -2.6820e+02  8e+01  1e-13  5e-16\n",
      " 3: -1.9912e+02 -2.0761e+02  8e+00  7e-14  4e-16\n",
      " 4: -2.0009e+02 -2.0147e+02  1e+00  1e-13  3e-16\n",
      " 5: -2.0026e+02 -2.0057e+02  3e-01  2e-13  3e-16\n",
      " 6: -2.0030e+02 -2.0035e+02  5e-02  2e-14  3e-16\n",
      " 7: -2.0031e+02 -2.0031e+02  3e-03  2e-13  3e-16\n",
      " 8: -2.0031e+02 -2.0031e+02  9e-05  2e-13  3e-16\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "svm3=mySVM(kernel = gk, penalty=C, sigma = s )\n",
    "svm3.fit(trainingdata_even, traininglabels_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14852741  0.10761196  0.75563507  0.          0.35504448  0.\n",
      "  0.19501527  0.71335371  0.40388899  0.25922856  0.40162857  0.23366651\n",
      "  0.32560425  0.94098657  0.57510225  0.43394686  0.82295792  0.23111014\n",
      "  0.05528104  0.86596139  0.          0.27683956  0.36228964  0.12955513\n",
      "  0.02141471  0.8933276   0.06539517  0.44510457  0.56350914  0.99999927\n",
      "  0.38811404  0.39178541  0.16021827  0.          0.06290882  0.\n",
      "  0.76978805  0.37878446  0.56912868  0.49910508  0.          0.20274561\n",
      "  0.7743776   0.43242211  0.22066152  0.2835847   0.          0.27339149\n",
      "  0.70915287  0.          0.65847064  0.          0.24278906  0.3139659\n",
      "  0.02346468  0.16795367  0.00700537  0.69310127  0.19948181  0.3503308\n",
      "  0.31985193  0.71025483  0.79268244  0.09804262  0.82773451  0.25022565\n",
      "  0.          0.49172355  0.66373345  0.26733185  0.73459374  0.73717449\n",
      "  0.34885283  0.65556657  0.80719062  0.456559    0.          0.          0.1615302\n",
      "  0.63673793  0.54519339  0.436833    0.06699522  0.3120906   0.\n",
      "  0.15815239  0.30256463  0.25717077  0.67273355  0.          0.\n",
      "  0.69275124  0.21187361  0.49049441  0.11634066  0.6471262   0.26769128\n",
      "  0.42885257  0.1572467   0.07556982  0.68399593  0.26828093  0.49940586\n",
      "  0.54410169  0.73631559  0.13336842  0.317484    0.27083031  0.80357612\n",
      "  0.66884918  0.          0.01842164  0.25830347  0.          0.64602433\n",
      "  0.          0.13896227  0.42578681  0.          0.87025877  0.\n",
      "  0.14599793  0.99999927  0.79623491  0.80090626  0.61685564  0.\n",
      "  0.99998661  0.33991324  0.27111537  0.47634636  0.09846282  0.38212301\n",
      "  0.99999974  0.86983809  0.          0.30469041  0.35616139  0.31302405\n",
      "  0.45642424  0.          0.07129358  0.90831764  0.68444343  0.03567036\n",
      "  0.08357694  0.73884812  0.27924595  0.71061437  0.72392873  0.16890373\n",
      "  0.17145597  0.07211428  0.          0.00666077  0.19139471  0.\n",
      "  0.89023328  0.77895761  0.45992059  0.99999883  0.69853726  0.09410258\n",
      "  0.51800971  0.29306883  0.99991605  0.          0.5647075   0.62224035\n",
      "  0.57743912  0.3344176   0.3781835   0.50108374  0.18010465  0.28644334\n",
      "  0.80341256  0.80950464  0.3028766   0.          0.          0.\n",
      "  0.90348784  0.01434158  0.2779899   0.88539433  0.61470867  0.58577838\n",
      "  0.68389515  0.04293091  0.35919021  0.57426267  0.3090082   0.20783863\n",
      "  0.55308784  0.          0.40938694  0.29325521  0.06532811  0.41736561\n",
      "  0.16712139  0.20574197  0.34269543  0.          0.          0.79854282\n",
      "  0.87041818  0.64176432  0.9850087   0.18361091  0.41551067  0.54836313\n",
      "  0.48418231  0.27542422  0.35849594  0.02408033  0.97636061  0.69433322\n",
      "  0.93628429  0.77043177  0.20258473  0.          0.          0.93741838\n",
      "  0.49076194  0.86250544  0.          0.29545591  0.          0.33352775\n",
      "  0.31579122  0.16815659  0.28165438  0.74193534  0.96140518  0.9999998\n",
      "  0.53369834  0.62988239  0.62554635  0.27498972  0.37015863  0.26525277\n",
      "  0.90258282  0.74610298  0.05625587  0.99993236  0.          0.89784862\n",
      "  0.49797833  0.          0.12929869  0.72029367  0.1929793   0.\n",
      "  0.45414794  0.          0.02712933  0.          0.27100683  0.27759647\n",
      "  0.40547971  0.65512472  0.90813356  0.04790337  0.7645864   0.38539936\n",
      "  0.37080493  0.61614104  0.          0.          0.42718721  0.45662735\n",
      "  0.          0.          0.76145808  0.36414812  0.          0.52116026\n",
      "  0.28557342  0.5267747   0.17982477  0.92451395  0.26524029  0.71843002\n",
      "  0.84264506  0.99999851  0.66690065  0.          0.51359402  0.52543298\n",
      "  0.57739857  0.29943666  0.51063079  0.23486805  0.36732632  0.99999844\n",
      "  0.99999993  0.          0.74314126  0.85776172  0.18956131  0.9999939\n",
      "  0.27723982  0.44718954  0.          0.47291641  0.81753165  0.2481724\n",
      "  0.93351627  0.99999906  0.09534394  0.86471669  0.          0.65160584\n",
      "  0.32372877  0.96121611  0.72698419  0.66387974  0.59157271  0.58608059\n",
      "  0.13608247  0.21733736  0.37750956  0.2540509   0.16987405  0.0698593   0.\n",
      "  0.17139915  0.86252883  0.03634892  0.29252181  0.16249891  0.97049761\n",
      "  0.65942853  0.          0.2124337   0.79399999  0.4924461   0.36635434\n",
      "  0.38685434  0.17419548  0.          0.39701549  0.          0.19656767\n",
      "  0.64700694  0.11512065  0.0141565   0.68341561  0.36816972  0.35453097\n",
      "  0.99999914  0.99999979  0.88919998  0.9755896   0.40632839  0.18524801\n",
      "  0.05645726  0.25521571  0.70649371  0.34712702  0.05739012  0.01459701\n",
      "  0.41812135  0.26946062  0.          0.1872026   0.00800732  0.\n",
      "  0.24803072  0.53030063  0.27373812  0.69603937  0.          0.02699811\n",
      "  0.55631085  0.41393238  0.54362459  0.          0.37011793  0.9068745\n",
      "  0.3141817   0.08255429  0.86687685  0.          0.83162417  0.29793985\n",
      "  0.          0.31977401  0.20322743  0.          0.47544232  0.33519782\n",
      "  0.38950124  0.24550231  0.143451    0.29315242  0.11934654  0.28563939\n",
      "  0.03812226  0.          0.36191545  0.          0.58341706  0.83721503\n",
      "  0.26380316  0.41727744  0.72551178  0.50841933  0.36237111  0.99999994\n",
      "  0.39401323  0.          0.98707515  0.          0.66114189  0.30473238\n",
      "  0.37672292  0.          0.          0.99999636  0.          0.99999985\n",
      "  0.61631613  0.78039432  0.          0.19791655  0.32967345  0.62794121\n",
      "  0.11729494  0.49476498  0.72529911  0.          0.3417175   0.53383917\n",
      "  0.39153813  0.94979534  0.          0.04423089  0.69606419  0.81159477\n",
      "  0.85296607  0.52465751  0.41912022  0.97307943  0.61915769  0.31642659\n",
      "  0.21533229  0.37508559  0.41060271  0.82032025  0.38762287  0.30213818\n",
      "  0.07609003  0.27242364  0.44339829  0.84339614  0.          0.4933051\n",
      "  0.30770494  0.92591056  0.29604193  0.26612669  0.81488338  0.81258672\n",
      "  0.17364176  0.57089439  0.          0.          0.          0.26022855\n",
      "  0.2518417   0.86344916  0.91114602  0.50923667  0.99999943  0.65752395\n",
      "  0.          0.91629128  0.99999937  0.27036394  0.31449011  0.46352781\n",
      "  0.46108387  0.07652365  0.41634774  0.40169196  0.          0.\n",
      "  0.16621484  0.87262951  0.23592969  0.          0.14932583  0.48143988\n",
      "  0.45602841  0.39364902  0.97588602  0.2345769   0.21979902  0.22530438\n",
      "  0.23166594  0.          0.63318342  0.14677026  0.64693613  0.55184526\n",
      "  0.58448472  0.66790763  0.1007786   0.          0.66596947  0.62287169\n",
      "  0.          0.61366871  0.04227579  0.69587856  0.18417437  0.83826848\n",
      "  0.33218759  0.48179388  0.61219925  0.32639696  0.16172984  0.0970975\n",
      "  0.3747912   0.46582749  0.51063784  0.67310072  0.07058123  0.54459603\n",
      "  0.0876673   0.31909997  0.          0.          0.15561698  0.46531899\n",
      "  0.          0.33841552  0.66530877  0.51188442  0.42081447  0.46065998\n",
      "  0.27521914  0.28237987  0.41344093  0.13840859  0.71094953  0.\n",
      "  0.36905382  0.22596665  0.46192003  0.46908497  0.          0.00121547\n",
      "  0.4923097   0.44044579  0.65759279  0.54550426  0.20363856  0.40165352\n",
      "  0.68737885  0.14009728  0.34406885  0.          0.71592955  0.75491075\n",
      "  0.23707887  0.32477625  0.27766339  0.          0.3583611   0.06542279\n",
      "  0.41858334  0.46255631  0.263911    0.037405    0.40535007  0.18424035\n",
      "  0.0642314   0.60519884  0.35133858  0.64644836  0.69808914  0.69791129\n",
      "  0.02307521  0.2941189   0.66894504  0.30341216  0.02998101  0.74329476\n",
      "  0.63536799  0.32314397  0.51075101  0.48773843  0.          0.684652\n",
      "  0.25499237  0.29813414  0.65342869  0.28303761  0.62505324  0.26269668\n",
      "  0.37685458  0.65537686  0.27597158  0.1398292   0.41918769  0.67760952\n",
      "  0.53481525  0.41890134  0.4429092   0.28515512  0.60899702  0.03804601\n",
      "  0.57121539  0.7817807   0.57439537  0.63994188  0.67486416  0.79388773\n",
      "  0.          0.          0.17154003  0.38939915  0.38128727  0.48053261\n",
      "  0.          0.07238803  0.44863235  0.24182748  0.495635    0.67033132\n",
      "  0.52176639  0.97744976  0.58442325  0.          0.21339994  0.48680638\n",
      "  0.30436824  0.10315649  0.63607513  0.19603054  0.05986872  0.55142233\n",
      "  0.01671169  0.03976081  0.06504332  0.09167423  0.44037305  0.64323978\n",
      "  0.63025859  0.63841772  0.38023166  0.37135891  0.19251308  0.47454401\n",
      "  0.36741136  0.70815786  0.62592365  0.56432281  0.73833653  0.02495494\n",
      "  0.53028699  0.01799892  0.46442445  0.02715871  0.5821576   0.59594439\n",
      "  0.55671065  0.15897201  0.54951521  0.          0.81170719  0.70495069\n",
      "  0.59479524  0.41731738  0.34909359  0.60572288  0.15946683  0.77648008\n",
      "  0.31648754  0.          0.05196394  0.06638108  0.08775572  0.1997126\n",
      "  0.66449649  0.57032781  0.17581377  0.77443022  0.32343329  0.46265219\n",
      "  0.52645286  0.          0.19240129  0.17137385  0.0106911   0.21098069\n",
      "  0.42292774  0.44167787  0.5494905   0.81775591  0.24955625  0.68363373\n",
      "  0.3108309   0.14280653  0.11114059  0.63370821  0.35487805  0.65432703\n",
      "  0.27418354  0.67424476  0.79591133  0.42773824  0.13900522  0.3137054\n",
      "  0.45050113  0.57317907  0.49249024  0.51615671  0.13226263  0.58692656\n",
      "  0.80273916  0.69073528  0.11924558  0.          0.          0.02119285\n",
      "  0.37523638  0.18611694  0.55417277  0.27208271  0.60269626  0.57920091\n",
      "  0.53124876  0.57518777  0.47383576  0.54341556  0.23621047  0.18481878\n",
      "  0.64894034  0.57033243  0.60349542  0.11931889  0.          0.55073524\n",
      "  0.00272332  0.45086442  0.20695586  0.38821697  0.18336252  0.72384076\n",
      "  0.51213665  0.3297827   0.          0.10072516  0.62399363  0.90849897\n",
      "  0.52824891  0.28921142  0.74607986  0.44861556  0.34038445  0.310009\n",
      "  0.59655151  0.60934739  0.          0.26321782  0.48160927  0.43018759\n",
      "  0.62294757  0.80354808  0.08960198  0.34856043  0.26066275  0.54254038\n",
      "  0.59396647  0.59355366  0.63926576  0.5836892   0.16691622  0.17626989\n",
      "  0.62700144  0.62945249  0.11978785  0.20608921  0.26500372  0.61068554\n",
      "  0.42026315  0.31212448  0.45323363  0.63201096  0.          0.          0.5642077\n",
      "  0.20760397  0.          0.24694499  0.64447968  0.04506223  0.34964642\n",
      "  0.61762661  0.32105667  0.89394687  0.40517458  0.63302932  0.94232279\n",
      "  0.18127187  0.84722162  0.81757394  0.75249805  0.49790502  0.29149957\n",
      "  0.57632521  0.22582599  0.18303058  0.61732298  0.6811833   0.34543967\n",
      "  0.55318957  0.59899231  0.14931665  0.12108687  0.85945835  0.52760143\n",
      "  0.          0.          0.68285584  0.          0.627794    0.3519023\n",
      "  0.59450147  0.06721442  0.38799665  0.37064028  0.57349582  0.21635944\n",
      "  0.89436188  0.40383666  0.52863881  0.          0.40211929  0.20523401\n",
      "  0.25326872  0.47168147  0.07628482  0.57339115  0.24789471  0.58003585\n",
      "  0.65033156  0.41770028  0.39128843  0.19792556  0.          0.05604005\n",
      "  0.61278246  0.47443103  0.51792701  0.68302319  0.47293359  0.60313496\n",
      "  0.52300444  0.54167416  0.66710775  0.25968003  0.63116523  0.68083134\n",
      "  0.07885451  0.40660357  0.57410423  0.63525788  0.07292205  0.11292512\n",
      "  0.39668107  0.          0.54982636  0.57409611  0.23861698  0.53725253\n",
      "  0.50881611  0.40263994  0.55210622  0.73451891  0.17630961  0.48177392\n",
      "  0.00523751  0.60721602  0.15309578  0.66777635  0.73815689  0.64378743\n",
      "  0.22371898  0.37631357  0.26679764  0.04850353  0.26665022  0.34994721\n",
      "  0.00824101  0.60847944  0.63891837  0.36601825  0.20607417  0.60539067\n",
      "  0.76627535  0.38249659  0.5689246   0.39735324  0.20773694  0.68717857\n",
      "  0.60427539  0.50836962  0.59560128  0.41818242  0.04567202  0.00824853\n",
      "  0.1211954   0.16895589  0.28153966  0.70725508  0.28539638  0.4771487\n",
      "  0.02550994  0.64329086  0.10577975  0.52840733  0.02382518  0.06781232\n",
      "  0.37933585  0.3173859   0.          0.43907286  0.59568401  0.76940058\n",
      "  0.26084208  0.55700336  0.          0.62166964  0.          0.28088761\n",
      "  0.26456524  0.64960314  0.          0.6676052   0.86858861  0.80270191\n",
      "  0.16181541  0.99951978  0.22384839  0.49959421  0.64034581  0.36888984\n",
      "  0.21270105  0.35246101  0.71098397  0.30984398  0.69170139  0.19863446\n",
      "  0.61584334  0.26282495  0.53051902  0.60437642  0.2136904   0.66629372\n",
      "  0.2135551   0.          0.363851    0.58688358  0.76041275  0.79232441\n",
      "  0.          0.61431562  0.00573387  0.37814157  0.65411588  0.53306835\n",
      "  0.61234796  0.66767147  0.52475636  0.49594611  0.67290446  0.24318172\n",
      "  0.          0.32877117  0.47504367  0.          0.58837454  0.6391172\n",
      "  0.50463484  0.79330427  0.4007925   0.62235462  0.38400997  0.6646847\n",
      "  0.22526806  0.64347205  0.05502834  0.72026459  0.28367808  0.43520799\n",
      "  0.18082623]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LMatt\\Anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel\\__main__.py:20: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "983"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= np.array([0 if alpha<10**(-3) else alpha for alpha in svm3.a])\n",
    "svm3.a = a\n",
    "pred = svm3.predict(train_images[:no])\n",
    "x = list(pred == label0[:no])\n",
    "print(a)\n",
    "sum(x[:no])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100L, 785L)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(trainingdata_even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
